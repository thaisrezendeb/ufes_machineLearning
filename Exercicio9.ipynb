{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercicio9.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNvocMcfxeziLuJ3Vp/C6W7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thaisrezendeb/ufes_machineLearning/blob/main/Exercicio9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UIm3F31tKe5"
      },
      "source": [
        "**9) Realize a classificação da base de dados Statlog (Image Segmentation) (disponível em http://archive.ics.uci.edu/ml/datasets/Statlog+%28Image+Segmentation%29) usando o esquema de validação hold-out. Para cada execução, selecione aleatoriamente 80% das amostras para treino e o restante para teste. Execute 5 vezes o treinamento e teste e retorne a acurácia, macro recall e macro precisão média para cada algoritmo.\n",
        "Faça a classificação usando:**\n",
        "\n",
        "**a) kNN com métrica de distância Euclidiana. Para selecionar o melhor valor de k divida a base de treinamento em duas partes iguais: uma para treinar e a outra para validar e encontrar o melhor valor de k;**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiPGT_mDtIXc"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import datetime as dt\n",
        "\n",
        "#pd.set_option('mode.chained_assignment', None)\n",
        "\n",
        "segment = pd.read_csv(\"segment.dat\", sep=\" \", header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47vzbs4e7Pi5"
      },
      "source": [
        "######################################################\n",
        "#Classificação por kNN usando distância de Mahalanobis\n",
        "######################################################\n",
        "def vizinho(base_train, base_test, kviz=1, conf=False, nclass=1):\n",
        "  acuracia_knn = 0\n",
        "  confusao = np.array(np.zeros((nclass, nclass))).astype(int)\n",
        "  \n",
        "  if kviz > 1:\n",
        "    vizinhos = np.array(np.zeros((kviz,2)), dtype=object)\n",
        "\n",
        "  #Verifica a distância de cada amostra da base de teste com cada uma das amostras da base de treinamento\n",
        "  for i, row in base_test.iterrows():\n",
        "    dist_min = 1000000\n",
        "    \n",
        "    if kviz > 1:\n",
        "      for n in range(0, kviz):\n",
        "        vizinhos[n][1] = dist_min\n",
        "\n",
        "    classif_new = row[base_test.shape[1]-1]\n",
        "\n",
        "    for j, row_next in base_train.iterrows():\n",
        "      dist = 0\n",
        "      for k in range(0, base_test.shape[1]-1):\n",
        "        #print(k)\n",
        "        dist = dist + np.power(row_next[k]-row[k],2)\n",
        "\n",
        "      dist = np.sqrt(dist)   \n",
        "      \n",
        "      if kviz == 1:\n",
        "        if dist < dist_min:\n",
        "          dist_min = dist\n",
        "          classif_new = row_next[base_test.shape[1]-1]\n",
        "      else: #Mais de um vizinho, matriz de vizinhos\n",
        "        for z in range(0, vizinhos.shape[0]):\n",
        "          if dist < vizinhos[z][1]:\n",
        "            #print(\"Deslocando vizinho\", i, j, z, dist, vizinhos[z][1])\n",
        "            #Desloca todos os vizinhos logo abaixo\n",
        "            for y in range(vizinhos.shape[0]-1, z, -1):\n",
        "              vizinhos[y][0] = vizinhos[y-1][0]\n",
        "              vizinhos[y][1] = vizinhos[y-1][1]\n",
        "            #Substitui valor menor\n",
        "            vizinhos[z][1] = dist\n",
        "            vizinhos[z][0] = row_next[base_test.shape[1]-1]\n",
        "            break\n",
        "\n",
        "    if kviz > 1:\n",
        "      viz_df = pd.DataFrame(vizinhos, columns=['classif', 'dist'], index=None)\n",
        "      classif_new = viz_df['classif'].value_counts().index[0]\n",
        "      #print(classif_new)\n",
        "\n",
        "    if row[base_test.shape[1]-1] == classif_new:\n",
        "      acuracia_knn = acuracia_knn + 1\n",
        "\n",
        "    if conf == True:\n",
        "      for m in range(0, nclass):\n",
        "        for n in range(0, nclass):\n",
        "           if row[base_test.shape[1]-1] == m and classif_new == n:\n",
        "              confusao[m][n] = confusao[m][n] + 1\n",
        "        \n",
        "  #  print(\"Classif original de\", i, \":\", row[6], \"nova classif\", classif_new)\n",
        "  acuracia_knn = np.divide(acuracia_knn, base_test.shape[0])\n",
        "\n",
        "  return acuracia_knn, confusao\n",
        "\n",
        "def idx_k(x):\n",
        "  return {\n",
        "      0 : 1,\n",
        "      1 : 3,\n",
        "      2 : 5,\n",
        "      3 : 7\n",
        "    }.get(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lx28NGs6xJt",
        "outputId": "c74a2abb-bf73-4bda-b5e6-25adf83d4cf7"
      },
      "source": [
        "hold = 5\n",
        "ac_total = 0\n",
        "num_class = 7\n",
        "conf_total = np.array(np.zeros((num_class, num_class))).astype(int)\n",
        "\n",
        "#validação por hold-out\n",
        "for i in range(0,hold):\n",
        "  sel_train = np.random.choice(segment.shape[0], round(segment.shape[0]*0.8), replace=False)\n",
        "  segment_train = segment.iloc[sel_train]\n",
        "  segment_test = segment.drop(sel_train)\n",
        "  #segment_train, segment_test = train_test_split(segment, train_size=0.8)\n",
        "\n",
        "  size = np.divide(segment_train.shape[0],2).astype(int)\n",
        "  seg_train1 = segment_train[:size]\n",
        "  seg_train2 = segment_train[size:]\n",
        "\n",
        "  #definiçao do valor de k\n",
        "  ac11,a = vizinho(seg_train1, seg_train2, kviz=1)\n",
        "  ac21,a = vizinho(seg_train1, seg_train2, kviz=3)\n",
        "  ac31,a = vizinho(seg_train1, seg_train2, kviz=5)\n",
        "#  ac41,a = vizinho(seg_train1, seg_train2, kviz=7)\n",
        "\n",
        "  ac12,a = vizinho(seg_train2, seg_train1, kviz=1)\n",
        "  ac22,a = vizinho(seg_train2, seg_train1, kviz=3)\n",
        "  ac32,a = vizinho(seg_train2, seg_train1, kviz=5)\n",
        "#  ac42,a = vizinho(seg_train2, seg_train1, kviz=7)\n",
        "\n",
        "  ac1 = (ac11 + ac12)/2\n",
        "  ac2 = (ac21 + ac22)/2\n",
        "  ac3 = (ac31 + ac32)/2\n",
        "#  ac4 = (ac41 + ac42)/2\n",
        "\n",
        "  print(\"\\nAcurácia NN:\")\n",
        "  print(\"1-NN: {:.2f}%\".format(ac1*100), \\\n",
        "        \"\\n3-NN: {:.2f}%\".format(ac2*100),\\\n",
        "        \"\\n5-NN: {:.2f}%\".format(ac3*100))#,\\\n",
        "        #\"\\n7-NN: {:.2f}%\".format(ac4*100))\n",
        "  \n",
        "  #Faz a classificação com o k \n",
        "#  k = np.array([ac1, ac2, ac3, ac4]).argmax()\n",
        "  k = np.array([ac1, ac2, ac3]).argmax()\n",
        "  k = idx_k(k)\n",
        "\n",
        "  ac, conf = vizinho(segment_train, segment_test, kviz=k, conf=True, nclass=num_class)\n",
        "  print(\"Acurácia para k = {} | hold = {}: {:.2f}%\".format(k, i+1, ac*100))\n",
        "  \n",
        "  #Faz somatório para apresentar médias\n",
        "  ac_total = ac_total + ac\n",
        "  conf_total = conf_total + conf\n",
        "\n",
        "#Acurácia média\n",
        "ac_total = ac_total/(hold)\n",
        "print(\"\\nAcurácia média (hold = {}): {:.2f}%\".format(hold, ac_total*100))\n",
        "\n",
        "#Macro precisão média (7 classes)\n",
        "conf_total = np.divide(conf_total, hold).astype(int)\n",
        "\n",
        "p = 0\n",
        "for i in range(0, num_class):\n",
        "  if conf_total.sum(axis=1)[i] != 0:\n",
        "    p = p + (conf_total[i][i] / conf_total.sum(axis=1)[i])\n",
        "        \n",
        "p = p/num_class\n",
        "print(\"\\nMacro precisão média: {:.2f}%\".format(p*100))\n",
        "\n",
        "#Macro recall médio\n",
        "r = 0\n",
        "for i in range(0, num_class):\n",
        "  if conf_total.sum(axis=0)[i] != 0:\n",
        "    r = r + (conf_total[i][i] / conf_total.sum(axis=0)[i])\n",
        "        \n",
        "r = r/num_class\n",
        "print(\"\\nMacro recall médio: {:.2f}%\".format(r*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Acurácia NN:\n",
            "1-NN: 94.37% \n",
            "3-NN: 92.37% \n",
            "5-NN: 91.23%\n",
            "Acurácia para k = 1 | hold = 1: 95.67%\n",
            "\n",
            "Acurácia NN:\n",
            "1-NN: 94.48% \n",
            "3-NN: 91.67% \n",
            "5-NN: 90.10%\n",
            "Acurácia para k = 1 | hold = 2: 95.89%\n",
            "\n",
            "Acurácia NN:\n",
            "1-NN: 94.26% \n",
            "3-NN: 92.32% \n",
            "5-NN: 90.48%\n",
            "Acurácia para k = 1 | hold = 3: 95.24%\n",
            "\n",
            "Acurácia NN:\n",
            "1-NN: 94.97% \n",
            "3-NN: 92.80% \n",
            "5-NN: 90.96%\n",
            "Acurácia para k = 1 | hold = 4: 96.75%\n",
            "\n",
            "Acurácia NN:\n",
            "1-NN: 93.89% \n",
            "3-NN: 92.26% \n",
            "5-NN: 90.69%\n",
            "Acurácia para k = 1 | hold = 5: 96.32%\n",
            "\n",
            "Acurácia média (hold = 5): 95.97%\n",
            "\n",
            "Macro precisão média: 82.61%\n",
            "\n",
            "Macro recall médio: 82.71%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aj3HT9EPu3Vw"
      },
      "source": [
        "**b) Use o Edit-kNN para classificar com métrica de distância Euclidiana. Pode ser usado o mesmo valor de k da letra a).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PcI5ACZu-JA"
      },
      "source": [
        "def edit_knn(base_train, base_test, kviz=1):\n",
        "  edit_base = pd.DataFrame(columns=base_train.columns)\n",
        "\n",
        "  if kviz > 1:\n",
        "    vizinhos = np.array(np.zeros((kviz,2)), dtype=object)\n",
        "\n",
        "  #Verifica a distância de cada amostra da base de teste com cada uma das amostras da base de treinamento\n",
        "  for i, row in base_test.iterrows():\n",
        "    dist_min = 1000000\n",
        "    \n",
        "    if kviz > 1:\n",
        "      for n in range(0, kviz):\n",
        "        vizinhos[n][1] = dist_min\n",
        "\n",
        "    classif_new = row[base_test.shape[1]-1]\n",
        "\n",
        "    for j, row_next in base_train.iterrows():\n",
        "      if j == i:\n",
        "        continue\n",
        "\n",
        "      dist = 0\n",
        "      for n in range(0, base_test.shape[1]-1):\n",
        "        dist = dist + np.power(row_next[n]-row[n],2)\n",
        "\n",
        "      dist = np.sqrt(dist)   \n",
        "      \n",
        "      if kviz == 1:\n",
        "        if dist < dist_min:\n",
        "          dist_min = dist\n",
        "          classif_new = row_next[base_test.shape[1]-1]\n",
        "      else: #Mais de um vizinho, matriz de vizinhos\n",
        "        for z in range(0, vizinhos.shape[0]):\n",
        "          if dist < vizinhos[z][1]:\n",
        "            #print(\"Deslocando vizinho\", i, j, z, dist, vizinhos[z][1])\n",
        "            #Desloca todos os vizinhos logo abaixo\n",
        "            for y in range(vizinhos.shape[0]-1, z, -1):\n",
        "              vizinhos[y][0] = vizinhos[y-1][0]\n",
        "              vizinhos[y][1] = vizinhos[y-1][1]\n",
        "            #Substitui valor menor\n",
        "            vizinhos[z][1] = dist\n",
        "            vizinhos[z][0] = row_next[base_test.shape[1]-1]\n",
        "            break\n",
        "\n",
        "    if kviz > 1:\n",
        "      viz_df = pd.DataFrame(vizinhos, columns=['classif', 'dist'], index=None)\n",
        "      classif_new = viz_df['classif'].value_counts().index[0]\n",
        "    \n",
        "    if row[base_test.shape[1]-1] != classif_new:\n",
        "      #Amostra desconhecida, mantém na base de dados\n",
        "      edit_base = edit_base.append(base_test.loc[i,:])\n",
        "        \n",
        "  return edit_base"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqrD9OIIVWmq",
        "outputId": "d4da1822-366d-4599-df52-b8465c4bdc0e"
      },
      "source": [
        "hold = 5\n",
        "num_class = 7\n",
        "k = 1\n",
        "ac_total = 0\n",
        "conf_total = np.array(np.zeros((num_class, num_class))).astype(int)\n",
        "\n",
        "#validação por hold-out\n",
        "for i in range(0,hold):\n",
        "  sel_train = np.random.choice(segment.shape[0], round(segment.shape[0]*0.8), replace=False)\n",
        "  segment_train = segment.iloc[sel_train]\n",
        "  segment_test = segment.drop(sel_train)\n",
        "  #segment_train, segment_test = train_test_split(segment, train_size=0.8)\n",
        "\n",
        "  size = np.divide(segment_train.shape[0],2).astype(int)\n",
        "  seg_train1 = segment_train[:size]\n",
        "  seg_train2 = segment_train[size:]\n",
        "  \n",
        "  #print(seg_train1.shape)\n",
        "  seg_train1 = edit_knn(seg_train1, seg_train1, kviz=k)\n",
        "  #print(seg_train1.shape)\n",
        "  seg_train2 = edit_knn(seg_train2, seg_train2, kviz=k)\n",
        "\n",
        "  seg_edit = pd.concat([seg_train1, seg_train2])\n",
        "  ac, conf = vizinho(seg_edit, segment_test, kviz=k, conf=True, nclass=num_class)\n",
        "  \n",
        "  print(\"\\nQuantidade de amostras antes do edit-kNN: {}\".format(segment_train.shape[0]))\n",
        "  print(\"Quantidade de amostras depois do edit-kNN: {}\".format(seg_edit.shape[0]))\n",
        "  print(\"Acurácia edit para k = {} | hold = {}: {:.2f}%\".format(k, i+1, ac*100))\n",
        "\n",
        "  #Faz somatório para apresentar médias\n",
        "  ac_total = ac_total + ac\n",
        "  conf_total = conf_total + conf\n",
        "\n",
        "#Acurácia média\n",
        "ac_total = ac_total/(hold)\n",
        "print(\"\\nAcurácia edit média (hold = {}): {:.2f}%\".format(hold, ac_total*100))\n",
        "\n",
        "#Macro precisão média (7 classes)\n",
        "conf_total = conf_total/(hold)\n",
        "\n",
        "p = 0\n",
        "for i in range(0, num_class):\n",
        "  if conf_total.sum(axis=1)[i] != 0:\n",
        "    p = p + (conf_total[i][i] / conf_total.sum(axis=1)[i])\n",
        "        \n",
        "p = p/num_class\n",
        "print(\"\\nMacro precisão média: {:.2f}%\".format(p*100))\n",
        "\n",
        "#Macro recall médio\n",
        "r = 0\n",
        "for i in range(0, num_class):\n",
        "  if conf_total.sum(axis=0)[i] != 0:\n",
        "    r = r + (conf_total[i][i] / conf_total.sum(axis=0)[i])\n",
        "        \n",
        "r = r/num_class\n",
        "print(\"\\nMacro recall médio: {:.2f}%\".format(r*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Quantidade de amostras antes do edit-kNN: 1848\n",
            "Quantidade de amostras depois do edit-kNN: 115\n",
            "Acurácia edit para k = 1 | hold = 1: 35.06%\n",
            "\n",
            "Quantidade de amostras antes do edit-kNN: 1848\n",
            "Quantidade de amostras depois do edit-kNN: 110\n",
            "Acurácia edit para k = 1 | hold = 2: 32.90%\n",
            "\n",
            "Quantidade de amostras antes do edit-kNN: 1848\n",
            "Quantidade de amostras depois do edit-kNN: 126\n",
            "Acurácia edit para k = 1 | hold = 3: 35.28%\n",
            "\n",
            "Quantidade de amostras antes do edit-kNN: 1848\n",
            "Quantidade de amostras depois do edit-kNN: 101\n",
            "Acurácia edit para k = 1 | hold = 4: 30.30%\n",
            "\n",
            "Quantidade de amostras antes do edit-kNN: 1848\n",
            "Quantidade de amostras depois do edit-kNN: 104\n",
            "Acurácia edit para k = 1 | hold = 5: 43.29%\n",
            "\n",
            "Acurácia edit média (hold = 5): 35.37%\n",
            "\n",
            "Macro precisão média: 33.24%\n",
            "\n",
            "Macro recall médio: 37.45%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pq86H1oGvL2j"
      },
      "source": [
        "**c) Compare os resultados, tempos de execução e número de protótipos usados por cada algoritmo. Considerando a distribuição das classes, você considera o valor da acurácia média relevante? Por quê?**\n",
        "\n",
        "Tempo de execução:\n",
        "- kNN: >4h\n",
        "- edit-kNN: ~45min\n",
        "\n",
        "Percebe-se que com o Edit-kNN o tempo de execução foi menor, o que só foi possível com a redução do número de protótipos. Porém, a redução do custo computacional interferiu significativamente no resultado da acurácia, mantendo aproximadamente 5% das amostras originais.\n",
        "\n",
        "Considerando que as amostras são selecionadas aleatoriamente, o uso da acurácia média pode fazer com que valores extremos não sejam impeditivos para avaliação do modelo. Sendo assim, o uso do hold-out juntamente com os valores médios oferece uma avaliação melhor da eficiência do modelo."
      ]
    }
  ]
}